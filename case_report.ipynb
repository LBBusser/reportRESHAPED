{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaped Case Notebook - Luyang Busser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Version: 2023-09-15-preview\n",
      "Endpoint URL: https://oai-potential-hires.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv('environment.env')\n",
    "\n",
    "# Access the environment variables\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Example usage of the loaded environment variables\n",
    "print(\"API Version:\", OPENAI_API_VERSION)\n",
    "print(\"Endpoint URL:\", AZURE_OPENAI_ENDPOINT)\n",
    "# Avoid printing sensitive information like API keys.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot: Azure OpenAI\n",
    "\n",
    "The following block of code allows you to make a connection with the Azure OpenAI API. We are curious on the way you will solve the case. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a type of artificial intelligence that is capable of creating new content or data that has not been explicitly programmed or inputted by humans. It uses advanced algorithms and deep learning techniques to analyze and learn from existing data, and then generate new data that is similar or related to the original data. This can include things like images, music, text, videos, and even entire virtual environments. Generative AI is often used in creative fields such as art, music, and design, but also has practical applications in areas such as medicine, finance, and engineering.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Setting up the Azure OpenAI client with required credentials and endpoint\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "# Define a prompt for the OpenAI Chat API\n",
    "prompt = \"\"\"\n",
    "Define Generative AI\n",
    "\"\"\"\n",
    "\n",
    "# Set a system and user message\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "# Request a completion from the OpenAI Chat API using the client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt35PotentialHires\", \n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    "    max_tokens=800,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Upload pdf file section (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "GLOBAL_LOADER = None\n",
    "\n",
    "# Create the file upload widget\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.pdf',  # Accept only PDF files\n",
    "    multiple=False,  # Allow uploading only one file\n",
    "    description='Upload PDF'\n",
    ")\n",
    "\n",
    "'''\n",
    "UI to upload selected PDF and load it using PyMuPDFLoader\n",
    "'''\n",
    "def process_uploaded_pdf(change):\n",
    "     global global_loader\n",
    "     if uploader.value:\n",
    "        # Get the uploaded file details\n",
    "        uploaded_file = uploader.value[0]\n",
    "        filename = uploaded_file['name']\n",
    "        \n",
    "        # Load and process the PDF with PyPDFLoader\n",
    "        loader = PyMuPDFLoader(filename)\n",
    "        pages = loader.load()\n",
    "\n",
    "        GLOBAL_LOADER = loader\n",
    "        # Display basic information about the PDF\n",
    "        num_pages = len(pages)\n",
    "        first_page_sample = pages[0].page_content[:500] if pages else \"No content found.\"\n",
    "        \n",
    "        # Output the results\n",
    "        print(f\"Uploaded file: {filename}\")\n",
    "        print(f\"Number of pages: {num_pages}\")\n",
    "        print(\"----------------------\")\n",
    "        print(\"Uploading complete!\")\n",
    "        \n",
    "# Attach the file processing function to the upload event\n",
    "uploader.observe(process_uploaded_pdf, names='value')\n",
    "\n",
    "# Display the upload widget\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More flexible when it comes to anwering deeper questions. And handle structural information of the documents and change from table format to text format etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter\n",
    "\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 380\n",
      "page_content='UNITED STATES\\nSECURITIES AND EXCHANGE COMMISSION\\nWashington, D.C. 20549\\n \\nFORM 10-K\\n \\n \\n☒\\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 \\n \\n \\nFor the Fiscal Year Ended June 30, 2023\\n \\n \\n \\nOR\\n \\n \\n☐\\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\n \\n \\n \\nFor the Transition Period From                  to\\nCommission File Number 001-37845 \\n \\nMICROSOFT CORPORATION\\n \\n \\nWASHINGTON\\n \\n91-1144442\\n(STATE OF INCORPORATION)' metadata={'source': 'Microsoft_2023_Trimmed.pdf', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'page': 0, 'total_pages': 39, 'format': 'PDF 1.4', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.5', 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'creationDate': \"D:20240416090710Z00'00'\", 'modDate': \"D:20240416160138Z00'00'\", 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_LOADER = PyMuPDFLoader(\"Microsoft_2023_Trimmed.pdf\")\n",
    "text = GLOBAL_LOADER.load()\n",
    "splits = r_splitter.split_documents(text)\n",
    "print(f\"Number of document chunks: {len(splits)}\")\n",
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be more compatible with underlying LLM, and the inherit token context length. But in the end less flexible and I do not know exact details of the limits anyway. So rather have benefits of a flexible splitter than maintains the structural hierarchy rather than the potential compatability of this.\n",
    "For real world application, when I know which model we are working with, I might be able to combine the best of both worlds and apply a hybrid approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=50, chunk_overlap=5)\n",
    "docs = text_splitter.split_documents(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open AI embedding (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m AzureOpenAIEmbeddings(\n\u001b[0;32m      7\u001b[0m     azure_deployment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt35PotentialHires\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     openai_api_version\u001b[38;5;241m=\u001b[39mOPENAI_API_VERSION,)\n\u001b[0;32m      9\u001b[0m vector_store_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/vector_store\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_store_dir\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_community\\vectorstores\\chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    777\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_community\\vectorstores\\chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    731\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    732\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    733\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    734\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    735\u001b[0m     ):\n\u001b[1;32m--> 736\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    742\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_community\\vectorstores\\chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_openai\\embeddings\\base.py:517\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_openai\\embeddings\\base.py:333\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    331\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 333\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    337\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\openai\\resources\\embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\openai\\_base_client.py:1232\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1220\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1229\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1230\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\openai\\_base_client.py:1012\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1011\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1016\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1020\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import openai\n",
    "\n",
    "#Encode text using Azure OpenAI Embeddings, unfortunately couldn't get it to work\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"gpt35PotentialHires\",\n",
    "    openai_api_version=OPENAI_API_VERSION,)\n",
    "vector_store_dir = \"data/vector_store\"\n",
    "\n",
    "#Store them into Chroma vector store\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=vector_store_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sentence-BERT instead and Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen the way I tried getting Azure Open AI embeddings would not work. So instead I started looking at open source free embedders on huggingface. I have worked with BERT models before and the sentence BERT made a lot of sense.\n",
    "\n",
    "Sentence BERT is particularly designed to efficiently be able to capture semantic meaning of sentences and allow direct comparison/ similarity search without any extra computational overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "persist_dir = \"data/vector_store\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'all-MiniLM-L6-v2', model_kwargs=model_kwargs) #SBERT embeddings\n",
    "# Create a vector store\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors stored: 380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='PART I\\nItem 1\\n \\nAs of June 30, 2023, we employed approximately 221,000 people on a full-time basis, 120,000 in the U.S. and 101,000 internationally. Of the total \\nemployed people, 89,000 were in operations, including manufacturing, distribution, product support, and consulting services; 72,000 were in product \\nresearch and development; 45,000 were in sales and marketing; and 15,000 were in general and administration. Certain employees are subject to \\ncollective bargaining agreements.\\nOur Culture', metadata={'author': '', 'creationDate': \"D:20240416090710Z00'00'\", 'creator': 'wkhtmltopdf 0.12.5', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240416160138Z00'00'\", 'page': 7, 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'source': 'Microsoft_2023_Trimmed.pdf', 'subject': '', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'total_pages': 39, 'trapped': ''}),\n",
       " Document(page_content='who are men. In this year’s report, we again expanded our pay equity data beyond the U.S. to report on 61 additional countries (up from 12 last year), \\nrepresenting 99.8% of our global Microsoft workforce.\\nIn addition, we began reporting on unadjusted median pay in our annual report, comparing total pay amounts for all employees regardless of factors such', metadata={'author': '', 'creationDate': \"D:20240416090710Z00'00'\", 'creator': 'wkhtmltopdf 0.12.5', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240416160138Z00'00'\", 'page': 8, 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'source': 'Microsoft_2023_Trimmed.pdf', 'subject': '', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'total_pages': 39, 'trapped': ''}),\n",
       " Document(page_content='market competitive.\\nIn order to manage our costs in a dynamic, competitive environment, in fiscal year 2023 we announced that base salaries of salaried employees would \\nremain at fiscal year 2022 levels. Pay increases continue to be available for rewards-eligible hourly and equivalent employees. We will continue our \\npractice of investing in stock for all rewards-eligible employees, salaried and hourly, and investing in bonuses for all eligible employees.\\n9', metadata={'author': '', 'creationDate': \"D:20240416090710Z00'00'\", 'creator': 'wkhtmltopdf 0.12.5', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240416160138Z00'00'\", 'page': 7, 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'source': 'Microsoft_2023_Trimmed.pdf', 'subject': '', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'total_pages': 39, 'trapped': ''})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of vectors stored:\", vector_store._collection.count())\n",
    "\n",
    "#Test query to see if results of vector store are sound.\n",
    "q = \"What is the employee count?\"\n",
    "\n",
    "vector_store.similarity_search(q, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence BERT and FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS is just an alternative vector store from Chroma. I have worked with faiss before, it is a lightweight package that works well across the board, has great tools integrated and is GPU optimised. But decided to go with Chroma, since its new for me and I wanted to see performance and capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "persist_dir = \"data/vector_store/FAISS\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'all-MiniLM-L6-v2', model_kwargs= model_kwargs)\n",
    "vector_store = FAISS.from_documents(documents= splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors stored: 380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='PART I\\nItem 1\\n \\nAs of June 30, 2023, we employed approximately 221,000 people on a full-time basis, 120,000 in the U.S. and 101,000 internationally. Of the total \\nemployed people, 89,000 were in operations, including manufacturing, distribution, product support, and consulting services; 72,000 were in product \\nresearch and development; 45,000 were in sales and marketing; and 15,000 were in general and administration. Certain employees are subject to \\ncollective bargaining agreements.\\nOur Culture', metadata={'source': 'Microsoft_2023_Trimmed.pdf', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'page': 7, 'total_pages': 39, 'format': 'PDF 1.4', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.5', 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'creationDate': \"D:20240416090710Z00'00'\", 'modDate': \"D:20240416160138Z00'00'\", 'trapped': ''}),\n",
       " Document(page_content='who are men. In this year’s report, we again expanded our pay equity data beyond the U.S. to report on 61 additional countries (up from 12 last year), \\nrepresenting 99.8% of our global Microsoft workforce.\\nIn addition, we began reporting on unadjusted median pay in our annual report, comparing total pay amounts for all employees regardless of factors such', metadata={'source': 'Microsoft_2023_Trimmed.pdf', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'page': 8, 'total_pages': 39, 'format': 'PDF 1.4', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.5', 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'creationDate': \"D:20240416090710Z00'00'\", 'modDate': \"D:20240416160138Z00'00'\", 'trapped': ''}),\n",
       " Document(page_content='market competitive.\\nIn order to manage our costs in a dynamic, competitive environment, in fiscal year 2023 we announced that base salaries of salaried employees would \\nremain at fiscal year 2022 levels. Pay increases continue to be available for rewards-eligible hourly and equivalent employees. We will continue our \\npractice of investing in stock for all rewards-eligible employees, salaried and hourly, and investing in bonuses for all eligible employees.\\n9', metadata={'source': 'Microsoft_2023_Trimmed.pdf', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'page': 7, 'total_pages': 39, 'format': 'PDF 1.4', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.5', 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'creationDate': \"D:20240416090710Z00'00'\", 'modDate': \"D:20240416160138Z00'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of vectors stored:\", vector_store.index.ntotal)\n",
    "\n",
    "#Test query to see if results of vector store are sound.\n",
    "q = \"What is the employee count?\"\n",
    "\n",
    "vector_store.similarity_search(q, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='DOCUMENTS INCORPORATED BY REFERENCE\\nPortions of the definitive Proxy Statement to be delivered to shareholders in connection with the Annual Meeting of Shareholders to be held on December 7, 2023 are incorporated by \\nreference into Part III.', metadata={'source': 'Microsoft_2023_Trimmed.pdf', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'page': 0, 'total_pages': 39, 'format': 'PDF 1.4', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.5', 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'creationDate': \"D:20240416090710Z00'00'\", 'modDate': \"D:20240416160138Z00'00'\", 'trapped': ''}),\n",
       " Document(page_content='PART I\\nItem 1A\\n \\nBusiness model competition\\nCompanies compete with us based on a growing variety of business models.\\n•Even as we transition more of our business to infrastructure-, platform-, and software-as-a-service business model, the license-based \\nproprietary software model generates a substantial portion of our software revenue. We bear the costs of converting original ideas into software', metadata={'source': 'Microsoft_2023_Trimmed.pdf', 'file_path': 'Microsoft_2023_Trimmed.pdf', 'page': 20, 'total_pages': 39, 'format': 'PDF 1.4', 'title': 'Form 10-K for Microsoft Corp filed 07/27/2023', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.5', 'producer': 'macOS Version 14.2.1 (Build 23C71) Quartz PDFContext, AppendMode 1.1', 'creationDate': \"D:20240416090710Z00'00'\", 'modDate': \"D:20240416160138Z00'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the LLM to use\n",
    "llm = AzureOpenAI(deployment_name = 'gpt35PotentialHires')\n",
    "#Example prompt\n",
    "user_prompt = \"What company is described in the document and what is their business model?\"\n",
    "#Obtain the top 5 most relevant and then return the top 2 from that pool based on MMR.\n",
    "vector_store.max_marginal_relevance_search(user_prompt, k=2, fetch_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query retriever (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here some test blocks that I just used for my understanding of the capabilities of langchain query retrievers. Not used to get end results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "document_content_description = \"yearly report microsoft 2023\"\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"chapter\",\n",
    "        description=\"The chapter the chunk is from and the part according to the content page of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the document the chunk is from\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAI\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(llm, vector_store, document_content_description,  metadata_field_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\n```json\n{\n    \"query\": \"employee number\",\n    \"filter\": \"eq(\\\"chapter\\\", \\\"Part 1\\\")\"\n}\n```\n\n\n<< Example 4. >>\nData Source:\n```json\n{\n    \"content\": \"Financial Statement of Microsoft Corporation\",\n    \"attributes\": {\n        \"year\": {\n            \"type\": \"string\",\n            \"description\": \"The fiscal year of the financial statement\"\n        },\n        \"revenue\": {\n            \"type\": \"integer\",\n            \"description\": \"Revenue in millions of dollars\"\n        },\n        \"net_income\": {\n            \"type\": \"integer\",\n            \"description\": \"Net income in millions of dollars\"\n        }\n    }\n}\n```\n\nUser Query:\nWhat is the net income and revenue of Microsoft in 2019?\n\nStructured Request:\n```json\n{\n    \"query\": \"\",\n    \"filter\": \"eq(\\\"year\\\", \\\"2019\\\")\"\n}\n```\n\n<< Example 5. >>\nData Source:\n```json\n{\n    \"content\": \"Lyrics of a song\",\n    \"attributes\": {\n        \"artist\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the song artist\"\n        },\n        \"length\": {\n            \"type\": \"\n raised following error:\nGot invalid JSON object. Error: Extra data: line 5 column 1 (char 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\json.py:176\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\json.py:147\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[1;34m(json_string, parser)\u001b[0m\n\u001b[0;32m    146\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\json.py:160\u001b[0m, in \u001b[0;36m_parse_json\u001b[1;34m(json_str, parser)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\json.py:120\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[1;34m(s, strict)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\json\\__init__.py:370\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    369\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 5 column 1 (char 80)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain\\chains\\query_constructor\\base.py:50\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     49\u001b[0m allowed_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 50\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparse_and_check_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\json.py:178\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot invalid JSON object. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m expected_keys:\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Extra data: line 5 column 1 (char 80)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat did the document say about employee number in part 1?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\retrievers.py:321\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    320\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    324\u001b[0m         result,\n\u001b[0;32m    325\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\retrievers.py:314\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 314\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain\\retrievers\\self_query\\base.py:202\u001b[0m, in \u001b[0;36mSelfQueryRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m    193\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get documents relevant for a query.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        List of relevant documents\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     structured_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_constructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    206\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructured_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\runnables\\base.py:4517\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4513\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4514\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4516\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4518\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4520\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\output_parsers\\base.py:178\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[0;32m    171\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\output_parsers\\base.py:179\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[0;32m    171\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    181\u001b[0m         config,\n\u001b[0;32m    182\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\output_parsers\\base.py:221\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain\\chains\\query_constructor\\base.py:63\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredQuery(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m allowed_keys}\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing text\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m raised following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Parsing text\n```json\n{\n    \"query\": \"employee number\",\n    \"filter\": \"eq(\\\"chapter\\\", \\\"Part 1\\\")\"\n}\n```\n\n\n<< Example 4. >>\nData Source:\n```json\n{\n    \"content\": \"Financial Statement of Microsoft Corporation\",\n    \"attributes\": {\n        \"year\": {\n            \"type\": \"string\",\n            \"description\": \"The fiscal year of the financial statement\"\n        },\n        \"revenue\": {\n            \"type\": \"integer\",\n            \"description\": \"Revenue in millions of dollars\"\n        },\n        \"net_income\": {\n            \"type\": \"integer\",\n            \"description\": \"Net income in millions of dollars\"\n        }\n    }\n}\n```\n\nUser Query:\nWhat is the net income and revenue of Microsoft in 2019?\n\nStructured Request:\n```json\n{\n    \"query\": \"\",\n    \"filter\": \"eq(\\\"year\\\", \\\"2019\\\")\"\n}\n```\n\n<< Example 5. >>\nData Source:\n```json\n{\n    \"content\": \"Lyrics of a song\",\n    \"attributes\": {\n        \"artist\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the song artist\"\n        },\n        \"length\": {\n            \"type\": \"\n raised following error:\nGot invalid JSON object. Error: Extra data: line 5 column 1 (char 80)"
     ]
    }
   ],
   "source": [
    "question = \"What did the document say about employee number in part 1?\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vector_store.as_retriever()\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n",
    "\n",
    "\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here some final experiments on Retrieval Question Anwering methodology in langchain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nPossible answers: \\n- Strategic and competitive risks\\n- Third parties claiming that the company infringes their intellectual property\\n- Claims and lawsuits against the company\\n- Operational risks, including excessive outages, data losses, and disruptions of online services if the company fails to maintain an adequate operations infrastructure.<|im_end|>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vector_store.as_retriever()\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a way to prompt the model to answer in specific way, useful to get slightly more consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Use professional wording and do not include any unreleated information.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The document describes a company that is not specified, but they use a variety of business models, including licensing software and infrastructure-, platform-, and software-as-a-service. They market and distribute their products and services through OEMs, direct, and distributors and resellers. The financial metrics of the company are disclosed in the MD&A or the Notes to Financial Statements (Part II, Item 8 of this Form 10-K).<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "question  = \"What company is described in the document and what is their business model?\"\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The company is facing intense competition, risk of intellectual property infringement, and claims and lawsuits against them. The company may also experience excessive outages, data losses, and disruptions of their online services if they fail to maintain an adequate operations infrastructure. The risks may adversely affect their business, financial condition, results of operations, cash flows, and the trading price of their common stock.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the main risks this company is facing?\"\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a temporary variable to store the vector store to allow use outside scope of cell/method\n",
    "global_vector_store = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from langchain_openai import AzureOpenAI\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "# Global variable to hold the vector store\n",
    "\n",
    "def load_db(file):\n",
    "    global global_vector_store\n",
    "\n",
    "    # load documents\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # split documents , you can tune the chunk size and overlap to see what gives most consistent results. \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Check if the global vector store already exists\n",
    "    if global_vector_store is None:\n",
    "        # define embedding, you can also change the embedding model to fit your needs.\n",
    "        model_kwargs = {'device': 'cpu'}\n",
    "        embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2', model_kwargs=model_kwargs)\n",
    "\n",
    "        # create vector database from data\n",
    "        # We could also try FAISS instead of Chroma, found results obtained by Chroma to be good enough for now.\n",
    "        global_vector_store = Chroma.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=\"data/vector_store\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Using existing vector store\")\n",
    "\n",
    "    # define retriever\n",
    "    template = \"\"\"Answer only the below question given the context. If you don't know the answer, just say that you don't know. Use only a few sentences maximum. Keep the answer as concise as possible. Keep it professional. Include page: and section: at the end which is the source of your answer.\n",
    "        {context}\n",
    "        Question: {question}\n",
    "        Answer:\"\"\"\n",
    "    QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
    "    # Define the LLM\n",
    "    llm = AzureOpenAI(\n",
    "    deployment_name=\"gpt35PotentialHires\",\n",
    "    max_tokens = 100,\n",
    "    temperature = 0.7,\n",
    "    stop = \"\\n\\n\"\n",
    "    \n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                           retriever=global_vector_store.as_retriever(),\n",
    "                                           return_source_documents=True,\n",
    "                                           chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbbus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\utils.py:159: UserWarning: WARNING! stop is not default parameter.\n",
      "                stop was transferred to model_kwargs.\n",
      "                Please confirm that stop is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa = load_db(\"Microsoft_2023_Trimmed.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbbus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " The document describes Industry Solutions, formerly Microsoft Consulting Services, and their business model is to provide consulting services to clients to help them build and implement technology solutions. page: 45, section: Industry Solutions\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "question  = \"What company is described in the document and what is their business model?\"\n",
    "\n",
    "result = qa({\"query\": question})\n",
    "print(\"-\"*100)\n",
    "print(result[\"result\"])\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " The company is facing strategic and competitive risks. Competition in the technology sector is intense, and the barriers to entry in many of the company's businesses are low. The company's competitors range in size from diversified global companies with significant research and development resources to small, specialized firms. Many of the areas in which the company competes evolve rapidly with changing and disruptive technologies, shifting user needs, and are subject to these risks. (Page: 1, Section: ITEM 1A)\n",
      "        \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "question  = \"What are the main risks this company is facing?\"\n",
    "\n",
    "result = qa({\"query\": question})\n",
    "print(\"-\"*100)\n",
    "print(result[\"result\"])\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting financial table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract financial table, using pdfplumber. I found that pyMuPdf loader was not giving clean results, contained a lot of special characters and information outside the tables. \n",
    "\n",
    "Note that I currently hardcoded the page to look for tables. Ideally, this will be done automatically. But for the purpose of the case and time management I decided to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the code to format the extracted data into a pandas dataframe:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "data = [['Revenue:', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
      "        ['Service and other', '', '', '147,216', '', '', '', '125,538', '', '', '', '97,014', ''],\n",
      "        ['Cost of revenue:', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
      "        ['Service and other', '', '', '48,059', '', '', '', '43,586', '', '', '', '34,013', ''],\n",
      "        ['Gross margin', '', '', '146,052', '', '', '', '135,620', '', '', '', '115,856', ''],\n",
      "        ['Sales and marketing', '', '', '22,759', '', '', '', '21,825', '', '', '', '20,117', ''],\n",
      "        ['Operating income', '', '', '88,523', '', '', '', '83,383', '', '', '', '69,916', ''],\n",
      "        ['Income before income taxes', '', '', '89,311', '', '', '', '83,716', '', '', '', '71,102', ''],\n",
      "        ['Net income', '', '$', '72,361', '', '', '$', '72,738', '', '', '$', '61,271', ''],\n",
      "        [None, None, None, None, '', None, None, None, '', None, None, None, ''],\n",
      "        ['Basic', '', '$', '9.72', '', '', '$', '9.70', '', '', '$', '8.12', ''],\n",
      "        ['Weighted average shares outstanding:', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
      "        ['Diluted', '', '', '7,472', '', '', '', '7,540', '', '', '', '7,608', '']]\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "print(df)\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "                                     0 1  2        3 4  5  6        7 8  9  10       11 12\n",
      "0                             Revenue:                    ...                              \n",
      "1                     Service and other           147,216           125,538           97,014\n",
      "2                      Cost of revenue:                                                  \n",
      "3                     Service and other            48,059            43,586           34,013\n",
      "4                          Gross margin           146,052           135,620          115,856\n",
      "5                   Sales and marketing            22,759            21,825           20,117\n",
      "6                     Operating income            88,523            83,383           69,916\n",
      "7            Income before income taxes            89,311            83,716           71,102\n",
      "8                            Net income        $  72,361        $  72,738           61,271\n",
      "9                                  NaN       None  None         None  None        None  None\n",
      "10                                Basic        $  9.72         $  9.70            $  8.12 \n",
      "11  Weighted average shares outstanding:                                                  \n",
      "12                              Diluted             7,472             7,540            7,608\n",
      "``` \n",
      "\n",
      "Note that the code creates a pandas dataframe from the extracted data using the `pd.DataFrame()` function. The resulting dataframe contains the data in a tabular format with appropriate headers and indexes. The `print()` function is then used to display the resulting dataframe.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Open the PDF file\n",
    "with pdfplumber.open(\"Microsoft_2023_Trimmed.pdf\") as pdf:\n",
    "    # Typically, financial tables might be at the last page\n",
    "    last_page = pdf.pages[-1]  # Adjust the page index as needed\n",
    "    # Extract table from the page\n",
    "    table = last_page.extract_tables()\n",
    "    # Convert the table to a DataFrame  \n",
    "    # Define a prompt for the OpenAI Chat API\n",
    "    prompt = \"\"\"\n",
    "    I have extracted a page with tabular data from a PDF document. Please only show how to format it into code that used to visualise it using pandas dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set a system and user message\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"The following text contains financial data extracted from a report: {table}\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt35PotentialHires\", \n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Print the response\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I let the LLM find and format the table to be used in visualisation using pandas. So use the output of the llm to put it into the data field below and we extract the table.\n",
    "\n",
    "I got several results, the following cells are examples of what the LLM outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "                            Revenue:                                       \n",
      "                   Service and other      147,216      125,538       97,014\n",
      "                    Cost of revenue:                                       \n",
      "                   Service and other       48,059       43,586       34,013\n",
      "                        Gross margin      146,052      135,620      115,856\n",
      "                 Sales and marketing       22,759       21,825       20,117\n",
      "                    Operating income       88,523       83,383       69,916\n",
      "          Income before income taxes       89,311       83,716       71,102\n",
      "                          Net income    $  72,361    $  72,738    $  61,271\n",
      "                                None None    None None    None None    None\n",
      "                               Basic    $    9.72    $    9.70    $    8.12\n",
      "Weighted average shares outstanding:                                       \n",
      "                             Diluted        7,472        7,540        7,608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    ['Revenue:', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
    "    ['Service and other', '', '', '147,216', '', '', '', '125,538', '', '', '', '97,014', ''],\n",
    "    ['Cost of revenue:', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
    "    ['Service and other', '', '', '48,059', '', '', '', '43,586', '', '', '', '34,013', ''],\n",
    "    ['Gross margin', '', '', '146,052', '', '', '', '135,620', '', '', '', '115,856', ''],\n",
    "    ['Sales and marketing', '', '', '22,759', '', '', '', '21,825', '', '', '', '20,117', ''],\n",
    "    ['Operating income', '', '', '88,523', '', '', '', '83,383', '', '', '', '69,916', ''],\n",
    "    ['Income before income taxes', '', '', '89,311', '', '', '', '83,716', '', '', '', '71,102', ''],\n",
    "    ['Net income', '', '$', '72,361', '', '', '$', '72,738', '', '', '$', '61,271', ''],\n",
    "    [None, None, None, None, '', None, None, None, '', None, None, None, ''],\n",
    "    ['Basic', '', '$', '9.72', '', '', '$', '9.70', '', '', '$', '8.12', ''],\n",
    "    ['Weighted average shares outstanding:', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
    "    ['Diluted', '', '', '7,472', '', '', '', '7,540', '', '', '', '7,608', '']\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.loc[:, df.apply(lambda col: col.nunique() > 1)]\n",
    "df.columns = [''] * df.shape[1]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Category       Q1-2020         Q2-2020         \\\n",
      "0                               Revenue:                                        \n",
      "1                      Service and other       147,216         125,538          \n",
      "2                       Cost of revenue:                                        \n",
      "3                      Service and other        48,059          43,586          \n",
      "4                           Gross margin       146,052         135,620          \n",
      "5                    Sales and marketing        22,759          21,825          \n",
      "6                       Operating income        88,523          83,383          \n",
      "7             Income before income taxes        89,311          83,716          \n",
      "8                             Net income    $   72,361      $   72,738      $   \n",
      "9                                  Basic    $     9.72      $     9.70      $   \n",
      "10  Weighted average shares outstanding:                                        \n",
      "11                               Diluted         7,472           7,540          \n",
      "\n",
      "    Q3-2020    \n",
      "0              \n",
      "1    97,014    \n",
      "2              \n",
      "3    34,013    \n",
      "4   115,856    \n",
      "5    20,117    \n",
      "6    69,916    \n",
      "7    71,102    \n",
      "8    61,271    \n",
      "9      8.12    \n",
      "10             \n",
      "11    7,608    \n"
     ]
    }
   ],
   "source": [
    "# replace the extracted data with your own\n",
    "data = [[['Revenue:', '', '', '', '', '', '', '', '', '', '', '', '']],\n",
    "        [['Service and other', '', '', '147,216', '', '', '', '125,538', '', '', '', '97,014', '']],\n",
    "        [['Cost of revenue:', '', '', '', '', '', '', '', '', '', '', '', '']],\n",
    "        [['Service and other', '', '', '48,059', '', '', '', '43,586', '', '', '', '34,013', '']],\n",
    "        [['Gross margin', '', '', '146,052', '', '', '', '135,620', '', '', '', '115,856', '']],\n",
    "        [['Sales and marketing', '', '', '22,759', '', '', '', '21,825', '', '', '', '20,117', '']],\n",
    "        [['Operating income', '', '', '88,523', '', '', '', '83,383', '', '', '', '69,916', '']],\n",
    "        [['Income before income taxes', '', '', '89,311', '', '', '', '83,716', '', '', '', '71,102', '']],\n",
    "        [['Net income', '', '$', '72,361', '', '', '$', '72,738', '', '', '$', '61,271', ''], [None, None, None, None, '', None, None, None, '', None, None, None, '']],\n",
    "        [['Basic', '', '$', '9.72', '', '', '$', '9.70', '', '', '$', '8.12', '']],\n",
    "        [['Weighted average shares outstanding:', '', '', '', '', '', '', '', '', '', '', '', '']],\n",
    "        [['Diluted', '', '', '7,472', '', '', '', '7,540', '', '', '', '7,608', '']]]\n",
    "\n",
    "# create the dataframe\n",
    "df = pd.DataFrame([row[0] for row in data], columns=['Category', '', '', 'Q1-2020', '', '', '', 'Q2-2020', '', '', '', 'Q3-2020', ''])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra testing with other PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbbus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\langchain_core\\utils\\utils.py:159: UserWarning: WARNING! stop is not default parameter.\n",
      "                stop was transferred to model_kwargs.\n",
      "                Please confirm that stop is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa_bonus = load_db(\"what_makes_in_context_work.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " The paper discusses the idea of in-context learning, which is a novel approach to learning that makes use of demonstrations, and the authors believe that it could lead to new insights and opportunities in NLP. page:001 section:We are glad that all reviewers ﬁnd that the paper is novel (8jk5, LQ6N, 92YB, 7E5P), of interest to the broader NLP community (LQ6N, 92YB, \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "question  = \"What is the main idea of this paper?\"\n",
    "\n",
    "result = qa_bonus({\"query\": question})\n",
    "print(\"-\"*100)\n",
    "print(result[\"result\"])\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " This research is focused on advancing the state-of-the-art in computer science and a broad range of other disciplines. Page: 10 Section: Microsoft Research\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "question  = \"What domain is this research for?\"\n",
    "\n",
    "result = qa_bonus({\"query\": question})\n",
    "print(\"-\"*100)\n",
    "print(result[\"result\"])\n",
    "print(\"-\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
